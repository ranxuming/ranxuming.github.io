<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Xuming Ran </title>
		<link rel="stylesheet" href="style.css">
		<style>
			.markdown-body {
				box-sizing: border-box;
				min-width: 200px;
				max-width: 980px;
				margin: 0 auto;
				padding: 45px;
			}
			@media (max-width: 767px) {
				.markdown-body {
					padding: 15px;
				}
				.left {
			    width: 100%;
			  }
			  .right {
			    width: 100%;
			  }
				.portrait {
					margin-bottom: 1em;
			  }
			}
			html {
			  width: 100vw;
			}
			body {
			  overflow-x: hidden;
			}
		</style>
	</head>
	<body class="markdown-body">

	 		<div class="row">
				<div class="column-picture left">
		 			<img class="portrait" src="photo/Xuming_Headshot.jpeg">
				</div>
				<div class="column-picture right">
				  <h2>Xuming Ran</h2>
				  <p>Research Engineer<br/>
				    <a href="https://www.shlab.org.cn/">AI for Science</a><br/>
				    <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a><br/><br/></p>

				  <p><a href="mailto:ranxuming@gmail.com">Email</a> &nbsp; &nbsp; | &nbsp; &nbsp; <a href="bio.html">Bio</a> &nbsp; &nbsp; | &nbsp; &nbsp; <a href="Xuming_CV.pdf">CV</a> &nbsp; &nbsp; | &nbsp; &nbsp; <a href="https://github.com/ranxuming/">GitHub</a>  &nbsp; &nbsp; | &nbsp; &nbsp; <a href="https://scholar.google.com/citations?user=oTZip-cAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp; &nbsp; | &nbsp; &nbsp; <a href="https://www.researchgate.net/profile/Xuming-Ran">Research Gate</a> &nbsp; &nbsp; | &nbsp; &nbsp; <a href="blog.html">Blog</a> </p> <br/>
				</div>  
				<p><b> Using generative models as a bridge to understand the biological and artificial intelligence.</b></p>
				<p>I aim to use the first principal intelligence theory to bridge the gap between artificial and biological intelligence. This theory of closed-loop transcription via rate reduction and information theory can help build a generative model that excels at image synthesis and novelty detection. Furthermore, the generative model can enhance the visual cortex computation because it shares the same property that the human or primate visual cortex's abstract attribute resembles the generative model's latent attribute. Since memory is associated with visual stimuli, we can investigate the relationship between the hippocampus and the visual cortex with a generative model. Additionally, we can apply the insights from memory to guide continual learning. Finally, I want to apply this new model to solve problems in science (e.g., biology, chemistry, and physics). </p>
				Generative model, Visual cortex computation, Memory modelling, Continual learning, AI for Science.
	
				<h4>Research Interests</h4>
                       <div class="row">
							<ul>
							<li>Generative model(e.g., VAE, PixelCNN, GAN, Glow, and Diffusion model) via first priciple of intellgince (Information theory and Closed-loop Transcription and <a href="https://www2.stat.duke.edu/~berger/papers/formal-def.pdf">Reference prior</a> )  </li>
							<li>Visual cortex computation via GM(e.g.,Visual cortex modeling, Neural encoding and decoding)   </li>
							<li>Memory modelling with Visual cortex computation (Hippocampus modelling) </li>
							<li>Continual learning via memory modelling (e.g., Excitation-inhibition balance, Learning method of NN, Self-supervised learning)  </li>
                            <li>Application of generative model with Continual learning  (e.g., Novelty detection, Image synthesis, AI for Science (<i>e.g.,</i>Structural variants detection(computational biology), Catalytic reaction(Chemistry))</li>
                            </ul>
                       	</div>
                      </div>
			<h2></h2>
			<h3>Projects</h3>
			<h4>Generative model for image synthesis and novelty detection</h4>
			<div class="row">
				<ul>
				<li>GAN for Text-to-image synthesis  </li>
			    <div class="column-picture left">
				    <img class="portrait" src="photo/project/Project1.GAN4T2I.png">
		        </div>
		        <p><b>[Paper]</b> <b>Background:</b> Text-to-Image is a significant problem in computer vision. <b>Question:</b> Recently, there are some problems in the quality and semantic consistency of the generated image. <b>Method:</b>In this paper we propose an approach for Text-to-Image synthesis by focusing on the perception. We use text embeddings to generate semantic feature maps before target images synthesis instead of generating target images directly. The ground truth semantic layouts are calculated by interpretable classification network, and we will learn to generate semantic layouts before inferring target images from them. <b>Result:</b>We have trained our approach on the CUB2011 dataset and verified the quality of its generation and the interpretability of the network in simple background and small scale feature generation. </p> 
				</ul>


		    
			<h2></h2>
			<h3>Publications</h3>
			    <ol list-style-type: lower-roman>
                  <li><b>Xuming Ran</b>, et al,  <a href="bio.html">Self-supervised deep learning encodes multi-modalities features of genome sequence for detecting complex structural variants</a>, Submit to:  <i>  Nature Machine Intelligence</i> , 2023.</li>
                  <li><b>Xuming Ran</b>, Jie Zhang, Ziyuan Ye, Haiyan Wu, Qi Xu, Huihui Zhou, and Quanying Liu. <a href="https://arxiv.org/abs/2111.15309">A computational framework to unify representation similarity and function in biological and artificial neural networks.</a> Under Review (Rivsion 1) at: <i> IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 2022.</li>
                  <li><b>Xuming Ran</b>, Mingkun Xu, Qi Xu, Huihui Zhou, and Quanying Liu. <a href="https://arxiv.org/abs/2010.01819">Bigeminal Priors Variational auto-encoder.</a> arXiv preprint arXiv:2010.01819, 2020.</li>
                  <li><b>Xuming Ran</b>, Mingkun Xu, Lingrui Mei, Qi Xu, and Quanying Liu. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608021004111">Detecting out-of-distribution samples via variational auto-encoder with reliable uncertainty estimation</a> <i>Neural Networks</i>, 2021.</li>
                  <li>Jie Yuan, <b>Xuming Ran</b>, Keyin Liu, Chen Yao, Yi Yao, Haiyan Wu, and Quanying Liu. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0165027021003769">Machine Learning Applications on Neuroimaging for Diagnosis and Prognosis of Epilepsy: A Review,</a> <i>Journal of neuroscience methods</i>, 2021 .</li>
                  <li>Lingrui Mei, <b>Xuming Ran</b>, and Jin Hu. <a href="https://ieeexplore.ieee.org/abstract/document/9002666">Weakly Supervised Attention Inference Generative Adversarial Network for Text-to-Image</a>, <i> 2019 IEEE Symposium Series on Computational Intelligence (SSCI)</i>, 2019.</li>
                  <li>Qi Xu, Jiangrong Shen, <b>Xuming Ran</b>, Huajin Tang, Gang Pan, and Jian K. Liu. <a href="https://ieeexplore.ieee.org/abstract/document/9580757">Robust transcoding sensory information with neural spikes</a>, <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2021.</li>
                  <li>Li Ma, Renjun Shuai, <b>Xuming Ran</b>, Wenjia Liu, and Chao Ye. <a href="https://link.springer.com/article/10.1007/s11517-020-02163-3">Combining DC-GAN with ResNet for blood cell image classification</a>, <i>Medical & biological engineering & computing</i> 58, no. 6 :1251-1264, 2020.</li>
                  <li>Qi Xu, Yuyuan Gao, Jiangrong Shen, Yaxin Li, <b>Xuming Ran</b>, Huajin Tang, Gang Pan, <a href="bio.html">Enhancing Adaptive History Reserving by Spiking Convolutional Block Attention Module in Recurrent Neural Networks</a>, <i> NeurIPS</i>, 2023.</li>
                  <li>Shan-Shan Li, Yu-Shi Jiang, Xue-Ling Luo, <b>Xuming Ran</b>, Yuqiang Li, Dong Wu, Cheng-Xue Pan, Peng-Ju Xia, <a href="bio.html">Photocatalytic Vinyl Radical-Mediated Multicomponent 1,4-/1,8-carboimination Across Alkynes and Olefins/(Hetero)Arenes</a>, <i> Science China Chemistry </i>, 2023.</li>
                  <li>Songming Zhang, Xiaofeng Chen, <b>Xuming Ran</b>, Zhongshan Li, Wenming Cao, <a href="bio.html">Even decision tree needs causality</a>, Under Review at: <i> IEEE Transactions on Neural Networks and Learning Systems</i>, 2022.</li>
                  <li>Hong Peng, Mingkun Xu  Bo Wang, Zheyu Yang,  <b>Xuming Ran</b>, Bo Li, Jiaohua Huo, Jing Pei, Yuanyuan Cui , Huafeng Xiao, Xin Lou, Cuiping Mao, Guangming Zhu, Liang zhang , Zheng You, Lin Ma,  <a href="bio.html">A New Virtual MR Contrast-enhancement Method based on Deep Learning: Faster, Safer, and Easier</a>, Under Review at: <i> Nature Machine Intelligence</i>, 2022.</li>
                  <li> Qi Xu, Sibo Liu, <b>Xuming Ran</b>, Yaxin Li, Jiangrong Shen, Huajin Tang, Jian K. Liu, and Gang Pan, <a href="bio.html">Robust Sensory Information Reconstruction and Classification with Augmented Spikes</a>, Under Review at: <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 2023. </li>
			    </ol>
			<h2></h2>
			<h3>Talks</h3>
                <ul>
                <li><a href="https://www.sustech.edu.cn/en/events/english-mapping-v4-to-artificial-neurons-via-autoencoder-allows-decoding-visual-informaion.html"><i>Mapping V4 to Artificial Neurons via Autoencoder allows Decoding Visual Information</i></a></li>
                <li><a href="https://math.sustech.edu.cn/applied/11898.html?lang=en"><i>Deep Generative Model for Out-of-distribution Detection</i></a></li>
				<li><a href="https://www.bilibili.com/video/BV1qL4y1s7V7/?spm_id_from=333.337.search-card.all.click&vd_source=6a872fcac11e47c14324ca8914bea7bf"><i>A computational framework to unify representation similarity and function in biological and artificial neural networks.</i></a></li>
				</ul>
			
			
			<h2></h2>
			<h3>Professional Service</h3>
			<h4>Conference Reviewing</h4>
			<ul>
			  <li><a href="https://conferences.miccai.org/2022/en/">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</a> </li>
			  <li><a href="https://2023.ijcnn.org/">International Joint Conference on Neural Networks (IJCNN) </a>  </li>
			  <li><a href="https://www.apnns.org/ICONIP2022//">International Conference on Neural Information Processing (ICONIP) </a>  </li>
			  <li><a href="https://wcci2022.org/">IEEE World Congress on Computational Intelligence (WCCI)  </a>  </li>
			  <li><a href="https://2023.fuzz-ieee.org/">IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) </a>  </li>
			  <li><a href="https://2023.ieee-cec.org/">IEEE Congress on Evolutionary Computation (CEC) </a> </li>
			 </ul>
			 <h4>Journal Reviewing</h4>
			<ul>
			  <li><a href="https://www.sciencedirect.com/journal/pattern-recognition">Pattern Recognition</a> </li>
			  <li><a href="https://www.sciencedirect.com/journal/pattern-recognition-letters">Pattern Recognition Letters </a> </li>
			  <li><a href="https://www.cell.com/heliyon/home">Heliyon </a>  </li>
			 </ul>


			 <h2></h2>
			 <h3>Summer School</h3>
			 <ul>
				<li><a href="http://brain.tsinghua.edu.cn/info/one/455">CNeuro: Computational and Theoretical Neuroscience Summer School</a>, Tsinghua Laboratory of Brain and Intelligence </li>
				<li><a href="https://www.csh-asia.org/?content/1159">AIBC: AI and Brain Computation Summer School </a>, Cold Spring Harbor Laboratory</li>
			   </ul>
			<h2></h2>
			 <h3></h3> 
</html>
