<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Human-in-the-Loop Machine Learning | University of Amsterdam</title>
		<link rel="stylesheet" href="style.css">
		<style>
			.markdown-body {
				box-sizing: border-box;
				min-width: 200px;
				max-width: 980px;
				margin: 0 auto;
				padding: 45px;
			}
			@media (max-width: 767px) {
				.markdown-body {
					padding: 15px;
				}
				.left {
			    width: 100%;
			  }
			  .right {
			    width: 100%;
			  }
				.portrait {
					margin-bottom: 1em;
			  }
			}
			html {
			  width: 100vw;
			}
			body {
			  overflow-x: hidden;
			}
		</style>
	</head>
	<body class="markdown-body">
	  <h2>Human-in-the-Loop Machine Learning</h2>
	  University of Amsterdam</br>
	  Masters of AI: Semester 1, Block 2, 2023</br>
	  Course Coordinators: <a href="https://enalisnick.github.io/">Eric Nalisnick</a> and <a href="https://aliannejadi.com/">Mohammad Aliannejadi</a></br>
	  Teaching Assistants: <a href="https://rajevv.github.io/">Rajeev Verma</a>, <a href="https://dvtailor.github.io/">Dharmesh Tailor<a></br> 
	  </br>

	  
	      <p>Machine learning (ML) is being deployed in increasingly consequential tasks, such as healthcare and autonomous driving.  For the foreseeable future, successfully deploying ML in such settings will require close collaboration and integration with humans, whether they be users, designers, engineers, policy-makers, etc.  This course will look at how humans can be incorporated into the foundations of ML in a principled way.  The course will be broken down (unequally) into three parts: <i>demonstration</i>, <i>collaboration</i>, and <i>oversight</i>.  Demonstration is about how machines can learn from 'observing' humans---such as learning to drive a car from data collected while humans drive.  In this setting, the human is assumed to be strictly better than the machine and so the primary goal is to transmit the human's knowledge and abilities into the ML model.  The second part, collaboration, is about when humans and models are near equals in performance but not in abilities.  A relevant setting is AI-assisted healthcare: perhaps a human radiologist and ML model are good at diagnosising different kinds of diseases.  Thus we will look at methodologies that allow machines to `ask for help' when they are either unconfident in their own performance and/or think the human can better carry out the task.  Lastly, the course will close with the setting in which machines are strictly better at a task than humans are, but we still wish to monitor them to ensure safety and alignment with our goals (oversight).</p>

	      <center><h3>Schedule and Topics</h3></center>
	      <table style="width: 100%">
		<thead>
		  <tr>
		    <th>Dates</th>
		    <th>Topics</th>
		    <th>Readings</th>
		  </tr>
		</thead>
		<tbody>
		  <tr>
		    <td colspan="3"><center><b>Part I:  Demonstration</b></center></td>
		  </tr>
		  <tr>
		    <td>31.10.23</td>
		    <td>Logistics, introduction, building prior knowledge into models</td>
		    <td>
		      <ol>
			<li><a href="https://staff.fnwi.uva.nl/m.welling/wp-content/uploads/Model-versus-Data-AI-1.pdf" target="_blank" rel="noopener noreferrer"><i>Do we still need models or just more data and compute?</i> by Welling</a></li>
			<li><a href="https://bayes.wustl.edu/etj/articles/prior.pdf" target="_blank" rel="noopener noreferrer"><i>Prior Probabilities</i> by Jaynes</a></li>
		      </ol>
		  </tr>
		  <tr>
		    <td>02.11.23</td>
		    <td>Crowdsourcing, Dawid-Skene model</td>
		    <td>
		      <ol>
			<li><a href="https://canvas.northwestern.edu/courses/65895/files/4174911/download?verifier=lUyedGR8Yb7I4NwFOtosvJqir8Oc6huVBwBgI5ko&wrap=1" target="_blank" rel="noopener noreferrer"><i>Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm</i> by Dawid &amp; Skene</a></li>
			<li><a href="https://jmlr.csail.mit.edu/papers/v11/raykar10a.html" target="_blank" rel="noopener noreferrer"><i>Learning From Crowds</i> by Raykar et al.</a></li>
			<li><a href="https://arxiv.org/abs/1703.08774" target="_blank" rel="noopener noreferrer"><i>Who Said What: Modeling Individual Labelers Improves Classification</i> by Guan et al.</a></li>
		      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>07.11.23</td>
		    <td>Active learning</td>
		    <td>
		      <ol>
			<li><a href="https://minds.wisconsin.edu/handle/1793/60660" target="_blank" rel="noopener noreferrer"><i>Active Learning Literature Survey</i> by Settles</a></li>
			<li><a href="https://icml.cc/Conferences/2011/papers/596_icmlpaper.pdf" target="_blank" rel="noopener noreferrer"><i>Active Learning from Crowds</i> by Yan et al.</a></li>
		      </ol>
		    </td>
		  </tr>
		  <tr>
		    <td>09.11.23</td>
		    <td>Practical on crowdsourcing platforms</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>14.11.23</td>
		    <td>Imitation learning: review of reinforcement learning (RL), behavior cloning, distribution matching</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>16.11.23</td>
		    <td>Imitation learning continued: inverse RL, RL from human feedback, direct preference optimization</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td colspan="3"><center><b>Part II:  Collaboration</b></center></td>
		  </tr>
		  <tr>
		    <td>21.11.23</td>
		    <td>Introduction to human-AI collaboration ('hybrid intelligence'), combining human and machine decisions</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>23.11.23</td>
		    <td>Learning to reject, learning to defer</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>30.11.23</td>
		    <td colspan="2"><center>Exam</center></td>
		  </tr>
		  <tr>
		    <td>05.12.23</td>
		    <td>AI-assisted decision making, multi-agent RL, collaborative inverse RL</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>07.12.23</td>
		    <td>Large language models: prompting and in-context learning as demonstration and collaboration</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td colspan="3"><center><b>Part III:  Oversight</b><center></td>
		  </tr>
		  <tr>
		    <td>12.12.23</td>
		    <td>AI alignment, off-switch game</td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>14.12.23</td>
		    <td>Iterated amplification, course summary</td>
		    <td></td>
		  </tr>
		</tbody>
	      </table>

	</body>
</html>
